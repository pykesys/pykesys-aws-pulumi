create a complete pulumi config that deploys the following to AWS:

iam config:

username: pykesys-infra, mfa enabled, mfa device 831-234-5678, this user will be used by terraform to deploy/modify/destroy all aws resources like ec2, efs, ebs, route53, etc.
username or role?: pykesys-db-user - used for webapp server to talk to db server
username or role?: pykesys-app-user - used to access webapp

architecture config:

EFS volume named pykesys-vol shared by all EC2 instances defined here:

EC2 instance provisioned by chef: app.pykesys.com: security group will allow traffic for openldap, nginx, php, : chef runlist: nginx, php, base
EC2 instance provisioned by chef: db.pykesys.com: security group will allow traffic for openldap, mysql: pulumi secret: db-password "passwordme" : chef runlist: mysql, base
EC2 instance provisioned by chef: noc.pykesys.com: security group will allow traffic for openldap, influxdb, grafana, sendmail, postfix : chef runlist: openldap, influxdb, grafana, sendmail, postfix, base

ROUTE53 accept all traffic to pykesys.com
and redirect web traffic to server webapp.pykesys.com
and redirect email traffic to noc.pykesys.com

---------------
Here is a **Pulumi configuration in TypeScript** that matches your specifications:

### Pulumi Project Setup

Before starting, make sure you have:

1. **Pulumi Installed**: Install the Pulumi CLI using [this guide](https://www.pulumi.com/docs/get-started/install/).
2. **AWS Credentials Configured**: Ensure your AWS CLI credentials are set up.
3. **Pulumi Project Created**: Run `pulumi new aws-typescript` to set up a new project.

---

### **`index.ts`** (Pulumi Configuration)

```typescript
import * as pulumi from "@pulumi/pulumi";
import * as aws from "@pulumi/aws";

// Configuration Variables
const config = new pulumi.Config();
const appAmiId = config.require("appAmiId");
const dbAmiId = config.require("dbAmiId");
const nocAmiId = config.require("nocAmiId");
const zoneId = config.require("zoneId");
const dbPassword = config.requireSecret("dbPassword"); // Pulumi secret for database password

// IAM User: pykesys-infra with MFA
const infraUser = new aws.iam.User("pykesys-infra", {
    name: "pykesys-infra",
});

const mfaDevice = new aws.iam.VirtualMfaDevice("pykesys-mfa-device", {
    virtualMfaDeviceName: "pykesys-infra-mfa",
    users: [infraUser.name],
});

new aws.iam.UserPolicy("pykesys-infra-policy", {
    user: infraUser.name,
    policy: JSON.stringify({
        Version: "2012-10-17",
        Statement: [
            {
                Action: "*",
                Effect: "Allow",
                Resource: "*",
            },
        ],
    }),
});

// IAM Roles for Application Access
const dbRole = new aws.iam.Role("pykesys-db-user", {
    assumeRolePolicy: JSON.stringify({
        Version: "2012-10-17",
        Statement: [
            {
                Action: "sts:AssumeRole",
                Effect: "Allow",
                Principal: { Service: "ec2.amazonaws.com" },
            },
        ],
    }),
});

const appRole = new aws.iam.Role("pykesys-app-user", {
    assumeRolePolicy: JSON.stringify({
        Version: "2012-10-17",
        Statement: [
            {
                Action: "sts:AssumeRole",
                Effect: "Allow",
                Principal: { Service: "ec2.amazonaws.com" },
            },
        ],
    }),
});

// VPC and Subnet
const vpc = new aws.ec2.Vpc("pykesys-vpc", { cidrBlock: "10.0.0.0/16" });

const subnet = new aws.ec2.Subnet("pykesys-subnet", {
    vpcId: vpc.id,
    cidrBlock: "10.0.1.0/24",
    mapPublicIpOnLaunch: true,
});

// EFS Volume
const efs = new aws.efs.FileSystem("pykesys-vol", {});

const efsMountTarget = new aws.efs.MountTarget("pykesys-vol-mount", {
    fileSystemId: efs.id,
    subnetId: subnet.id,
});

// Security Groups
const createSecurityGroup = (name: string, ingressRules: aws.types.input.ec2.SecurityGroupIngress[]) => {
    return new aws.ec2.SecurityGroup(name, {
        vpcId: vpc.id,
        ingress: ingressRules,
        egress: [
            { protocol: "-1", fromPort: 0, toPort: 0, cidrBlocks: ["0.0.0.0/0"] },
        ],
    });
};

const appSg = createSecurityGroup("app-sg", [
    { protocol: "tcp", fromPort: 80, toPort: 80, cidrBlocks: ["0.0.0.0/0"] },
    { protocol: "tcp", fromPort: 443, toPort: 443, cidrBlocks: ["0.0.0.0/0"] },
]);

const dbSg = createSecurityGroup("db-sg", [
    { protocol: "tcp", fromPort: 3306, toPort: 3306, cidrBlocks: ["10.0.0.0/16"] },
]);

const nocSg = createSecurityGroup("noc-sg", [
    { protocol: "tcp", fromPort: 389, toPort: 389, cidrBlocks: ["10.0.0.0/16"] },
    { protocol: "tcp", fromPort: 8086, toPort: 8086, cidrBlocks: ["10.0.0.0/16"] },
]);

// EC2 Instances with Chef Provisioning
const createInstanceWithChef = (
    name: string,
    ami: string,
    securityGroup: aws.ec2.SecurityGroup,
    tags: Record<string, string>,
    chefRunList: string[]
) => {
    const userDataScript = `#!/bin/bash
    set -e
    curl -L https://omnitruck.chef.io/install.sh | bash
    mkdir -p /etc/chef
    echo '{
        "run_list": ${JSON.stringify(chefRunList)}
    }' > /etc/chef/first-boot.json
    chef-client -j /etc/chef/first-boot.json
    `;
    return new aws.ec2.Instance(name, {
        ami: ami,
        instanceType: "t2.micro",
        subnetId: subnet.id,
        securityGroups: [securityGroup.name],
        tags: tags,
        userData: userDataScript,
    });
};

const appInstance = createInstanceWithChef(
    "app-instance",
    appAmiId,
    appSg,
    { Name: "app.pykesys.com" },
    ["recipe[nginx]", "recipe[php]", "recipe[base]"]
);

const dbInstance = createInstanceWithChef(
    "db-instance",
    dbAmiId,
    dbSg,
    { Name: "db.pykesys.com" },
    ["recipe[mysql::server]", "recipe[base]"]
);

const nocInstance = createInstanceWithChef(
    "noc-instance",
    nocAmiId,
    nocSg,
    { Name: "noc.pykesys.com" },
    ["recipe[openldap]", "recipe[influxdb]", "recipe[grafana]", "recipe[sendmail]", "recipe[postfix]", "recipe[base]"]
);

// Route 53 Records
const createDnsRecord = (name: string, targetInstance: aws.ec2.Instance) => {
    return new aws.route53.Record(name, {
        zoneId: zoneId,
        name: `${name}.pykesys.com`,
        type: "A",
        ttl: 300,
        records: [targetInstance.publicIp],
    });
};

createDnsRecord("app", appInstance);
createDnsRecord("db", dbInstance);
createDnsRecord("noc", nocInstance);

new aws.route53.Record("pykesys-com-redirect", {
    zoneId: zoneId,
    name: "pykesys.com",
    type: "CNAME",
    ttl: 300,
    records: ["app.pykesys.com"],
});
```

---

### Key Features

1. **IAM with MFA**: Includes `pykesys-infra` user with an attached MFA device.
2. **Chef Provisioning**: Bootstraps instances with Chef recipes using `userData`.
3. **Pulumi Secrets**: Database password is securely stored using Pulumi secrets.
4. **Route 53**: DNS configuration for `pykesys.com` and subdomains.
5. **EFS Volume**: Shared storage for all instances.

---

### Steps to Deploy

1. **Set up Pulumi project**:
   ```bash
   pulumi new aws-typescript
   ```

2. **Set Configurations**:
   ```bash
   pulumi config set appAmiId <APP_AMI_ID>
   pulumi config set dbAmiId <DB_AMI_ID>
   pulumi config set nocAmiId <NOC_AMI_ID>
   pulumi config set zoneId <ROUTE53_ZONE_ID>
   pulumi config set --secret dbPassword "passwordme"
   ```

3. **Preview and Deploy**:
   ```bash
   pulumi preview
   pulumi up
   ```

---

Let me know if you need further refinements! ðŸš€

===============

what about using chefzero

-----------

Using **Chef Zero** (a lightweight, in-memory Chef server that runs locally) is a great alternative when you don't want to set up a full Chef server. It simplifies the configuration process while retaining the power of Chef recipes and cookbooks. Here's how you can configure your Pulumi setup to use Chef Zero:

---

### **Chef Zero Overview**
- Chef Zero acts as a standalone, temporary Chef server.
- You can run it locally on each EC2 instance.
- It eliminates the need for a dedicated Chef server but still uses the same `client.rb` and cookbooks.

---

### **Updated Pulumi Code with Chef Zero**

Below is an updated Pulumi configuration that uses Chef Zero for provisioning EC2 instances.

#### **User Data Script for Chef Zero**

```typescript
const createInstanceWithChefZero = (
    name: string,
    ami: string,
    securityGroup: aws.ec2.SecurityGroup,
    tags: Record<string, string>,
    chefCookbooksUrl: string,
    chefRunList: string[]
) => {
    const userDataScript = `#!/bin/bash
set -e

# Install Chef Client
curl -L https://omnitruck.chef.io/install.sh | bash

# Download and Configure Cookbooks
mkdir -p /tmp/chef-repo/cookbooks
cd /tmp/chef-repo
curl -L ${chefCookbooksUrl} | tar -xz -C cookbooks

# Generate Chef Configuration
mkdir -p /etc/chef
cat <<EOF > /etc/chef/client.rb
log_level        :info
log_location     STDOUT
chef_server_url  "http://localhost:8889"
EOF

cat <<EOF > /etc/chef/first-boot.json
{
  "run_list": ${JSON.stringify(chefRunList)}
}
EOF

# Start Chef Zero in the Background
chef-zero --host 0.0.0.0 --port 8889 &
sleep 5 # Wait for Chef Zero to start

# Run Chef Client
chef-client -j /etc/chef/first-boot.json
`;

    return new aws.ec2.Instance(name, {
        ami: ami,
        instanceType: "t2.micro",
        subnetId: subnet.id,
        securityGroups: [securityGroup.name],
        tags: tags,
        userData: userDataScript,
    });
};
```

---

#### **Usage Example**
This function can be called just like the original `createInstanceWithChef` function. The difference is that `chefCookbooksUrl` points to a tarball of your cookbooks.

```typescript
const appInstance = createInstanceWithChefZero(
    "app-instance",
    appAmiId,
    appSg,
    { Name: "app.pykesys.com" },
    "https://example.com/cookbooks.tar.gz", // URL to cookbooks archive
    ["recipe[nginx]", "recipe[php]", "recipe[base]"]
);

const dbInstance = createInstanceWithChefZero(
    "db-instance",
    dbAmiId,
    dbSg,
    { Name: "db.pykesys.com" },
    "https://example.com/cookbooks.tar.gz",
    ["recipe[mysql::server]", "recipe[base]"]
);

const nocInstance = createInstanceWithChefZero(
    "noc-instance",
    nocAmiId,
    nocSg,
    { Name: "noc.pykesys.com" },
    "https://example.com/cookbooks.tar.gz",
    ["recipe[openldap]", "recipe[influxdb]", "recipe[grafana]", "recipe[sendmail]", "recipe[postfix]", "recipe[base]"]
);
```

---

### **Steps to Use Chef Zero**

1. **Package Your Cookbooks**:
   - Archive your cookbooks into a tarball (e.g., `cookbooks.tar.gz`).
   - Host the tarball on a public or private URL accessible by the EC2 instances.

   ```bash
   tar -czf cookbooks.tar.gz cookbooks/
   ```

2. **Customize the Script**:
   - Ensure `chef-zero` is installed using the Chef installer.
   - Start `chef-zero` as part of the user data script.
   - Use the `chef-client` to run recipes against the local Chef Zero instance.

3. **Run Chef Zero Locally**:
   - Chef Zero runs in-memory and provides a temporary Chef server on `localhost`.
   - The EC2 instance connects to `http://localhost:8889` as its Chef server.

---

### **Advantages of Chef Zero**
- No need to set up and maintain a Chef server.
- Fully autonomous configuration on each instance.
- Simpler for small-scale deployments.

---

Let me know if you'd like more details about packaging or hosting the cookbooks!

